{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/8OxY8qxd0z4O442eFUuI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yumax-panda/YOLO-research/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install required packages and import modules"
      ],
      "metadata": {
        "id": "SSvlXtqEKaEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics fastai"
      ],
      "metadata": {
        "id": "AW7pUNU9KmYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4yal7eOEKce4"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from fastai.vision.all import untar_data, URLs, set_seed, parent_label, get_image_files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funcs\n",
        "\n",
        "https://github.com/fastai/imagenette/blob/master/noisy_labels/generate_labels.ipynb"
      ],
      "metadata": {
        "id": "c79rLtv7NMNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels(files):\n",
        "    labels = []\n",
        "    for file in files: labels.append(parent_label(file))\n",
        "    return labels\n",
        "\n",
        "def generate_noisy_labels(labels,unique_labels,pct_noise):\n",
        "    noisy_labels = labels.copy() #copy labels list, this is will be the new list with noisy labels\n",
        "    num_labels = len(labels) #number of labels\n",
        "    num_classes = len(unique_labels) #number of unique labels\n",
        "    noisy_idxs = [] #this is the list of indices where the labels will be switched\n",
        "    indices = np.random.permutation(num_labels) #randomly permute the indices\n",
        "    for i, idx in enumerate(indices):\n",
        "        if i < pct_noise * num_labels: # only change the first pct_noise% of the permuted labels\n",
        "            noisy_idxs.append(idx) #append to noisy_idxs\n",
        "            before_label = noisy_labels[idx]\n",
        "            while noisy_labels[idx] == before_label: #ensure that the new label isn't the same\n",
        "                new_label = unique_labels[np.random.randint(num_classes)] #randomly select a new label\n",
        "                noisy_labels[idx] = new_label  #assign new label\n",
        "    return noisy_labels, noisy_idxs\n",
        "\n",
        "def get_imagenette_relative_path(files):\n",
        "    _files = []\n",
        "    for i in range(len(files)): _files.append(os.path.join(*str(files[i]).split('/')[-3:]))\n",
        "    return _files"
      ],
      "metadata": {
        "id": "9JpJ2lq0ArY4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load imagewoof data"
      ],
      "metadata": {
        "id": "ocTBCzb8CK5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "__datasets_path__ = \"/content/datasets\"\n",
        "src = untar_data(URLs.IMAGEWOOF_160, data=__datasets_path__)\n",
        "print(src)\n",
        "train_files = get_image_files(src/\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "LZgz3HJ0CKZA",
        "outputId": "f077209b-0243-4eae-a725-a1340a55d844"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='92618752' class='' max='92612825' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.01% [92618752/92612825 00:03&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets/imagewoof2-160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = get_labels(train_files)\n",
        "unique_labels = list(set(labels))\n",
        "print(unique_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnlcJt8NCcfc",
        "outputId": "f5397c23-fbb7-4c2b-ff8f-ea8372ee719a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['n02086240', 'n02105641', 'n02093754', 'n02087394', 'n02111889', 'n02115641', 'n02089973', 'n02088364', 'n02096294', 'n02099601']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create noisy labels for imagewoof"
      ],
      "metadata": {
        "id": "gCtmldGtCtNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_labels_1, noisy_idxs_1 = generate_noisy_labels(labels, unique_labels, 0.01)\n",
        "print(f'percentage noise: {100*len(noisy_idxs_1)/len(noisy_labels_1)}%')\n",
        "\n",
        "example_idx = np.random.randint(len(noisy_idxs_1))\n",
        "print(noisy_labels_1[noisy_idxs_1[example_idx]], labels[noisy_idxs_1[example_idx]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tiq-wHLBCwZT",
        "outputId": "5692fe51-4119-4439-eb56-f4675a54c1a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "percentage noise: 1.0083102493074791%\n",
            "n02086240 n02089973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_labels_5, noisy_idxs_5 = generate_noisy_labels(labels, unique_labels, 0.05)\n",
        "noisy_labels_25, noisy_idxs_25 = generate_noisy_labels(labels, unique_labels, 0.25)\n",
        "noisy_labels_50, noisy_idxs_50 = generate_noisy_labels(labels, unique_labels, 0.50)"
      ],
      "metadata": {
        "id": "_CJz0swyDDhf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_files = get_imagenette_relative_path(train_files)\n",
        "train_df = pd.DataFrame({'path': _files,\n",
        "              'noisy_labels_1': noisy_labels_1,\n",
        "              'noisy_labels_5': noisy_labels_5,\n",
        "              'noisy_labels_25': noisy_labels_25,\n",
        "              'noisy_labels_50': noisy_labels_50,\n",
        "              'is_valid': [False]*len(_files)\n",
        "             })"
      ],
      "metadata": {
        "id": "nD79rtULDIO3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_files = get_image_files(src/'val')\n",
        "labels = get_labels(val_files)\n",
        "_files = get_imagenette_relative_path(val_files)\n",
        "val_df = pd.DataFrame({'path': _files,\n",
        "              'noisy_labels_1': labels,\n",
        "              'noisy_labels_5': labels,\n",
        "              'noisy_labels_25': labels,\n",
        "              'noisy_labels_50': labels,\n",
        "              'is_valid': [True]*len(_files)\n",
        "             })"
      ],
      "metadata": {
        "id": "JJyX2nDDDR5k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([train_df,val_df])"
      ],
      "metadata": {
        "id": "6ZRdqLn1Doh0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "print(f\"train datasize: {len(train_df)}\")\n",
        "print(f\"val datasize: {len(val_df)}\")\n",
        "print(f\"total: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDUYB_ZYDqCV",
        "outputId": "b3b1ec53-2dbb-4c5f-fced-61d084aac827"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train datasize: 9025\n",
            "val datasize: 3929\n",
            "total: 12954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('noisy_imagewoof.csv', index=False)"
      ],
      "metadata": {
        "id": "8juNLae8DtNt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create datasets"
      ],
      "metadata": {
        "id": "Z64wJY2yR0ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_noisy_datasets(df: pd.DataFrame, name:str, column_idx: int) -> None:\n",
        "  labels = ['n02111889', 'n02088364', 'n02096294', 'n02086240', 'n02089973', 'n02099601', 'n02105641', 'n02087394', 'n02115641', 'n02093754']\n",
        "\n",
        "  try:\n",
        "      os.mkdir(f\"{__datasets_path__}/{name}\")\n",
        "      os.mkdir(f\"{__datasets_path__}/{name}/train\")\n",
        "      os.mkdir(f\"{__datasets_path__}/{name}/val\")\n",
        "\n",
        "      for label in labels:\n",
        "        os.mkdir(f\"{__datasets_path__}/{name}/train/{label}\")\n",
        "        os.mkdir(f\"{__datasets_path__}/{name}/val/{label}\")\n",
        "\n",
        "  except FileExistsError:\n",
        "    print(\"already exists\")\n",
        "\n",
        "  _col_idx_mapping = {}\n",
        "\n",
        "  for idx, col in enumerate(df.columns, 0):\n",
        "    _col_idx_mapping[col] = idx\n",
        "\n",
        "  for row in df.values:\n",
        "    path, noisy_label = row[0], row[column_idx]\n",
        "    segments = path.split(\"/\", 2)\n",
        "    new_path = f\"{segments[0]}/{noisy_label}/{segments[-1]}\"\n",
        "\n",
        "    shutil.copyfile(f\"{__datasets_path__}/imagewoof2-160/{path}\", f\"{__datasets_path__}/{name}/{new_path}\")\n",
        ""
      ],
      "metadata": {
        "id": "TOxPA4nTJWNu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "  # noisy_labels = [\"noisy_labels_1\",\t\"noisy_labels_5\", \"noisy_labels_25\", \"noisy_labels_50\"]\n",
        "  noisy_labels = [\"noisy_labels_50\"] # to prevent memory error, we use only 50% noised datasets\n",
        "\n",
        "  # no noise datasets\n",
        "  # model = YOLO('yolov8n-cls.pt')\n",
        "  # result = model.train(data=\"imagewoof160\", epochs=1, imgsz=224)\n",
        "  # model.export(format='onnx')\n",
        "  # model(\"https://image.peppynet.com/rv/renewal/archive/golden-retriever/images/main-img.png\", save=True)\n",
        "\n",
        "  for idx, noisy_label in enumerate(noisy_labels):\n",
        "    print(f\"\\n\\nStarting: {noisy_label}\")\n",
        "    create_noisy_datasets(df, noisy_label, idx+1)\n",
        "    model = YOLO('yolov8n-cls.pt')\n",
        "    result = model.train(data=f\"{__datasets_path__}/{noisy_label}\", epochs=1, imgsz=224)\n",
        "    model.export(format='onnx')\n",
        "    model(\"https://image.peppynet.com/rv/renewal/archive/golden-retriever/images/main-img.png\", save=True)\n",
        ""
      ],
      "metadata": {
        "id": "ZzeCc2e3JiSr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "id": "Y6SDS41dSn4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run()"
      ],
      "metadata": {
        "id": "vmmNyE1ZSnYj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate"
      ],
      "metadata": {
        "id": "tCA5o6GmEyhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# After session is deleted, this util func must be called before using datasets\n",
        "def setup():\n",
        "  for idx, col in enumerate([\"noisy_labels_1\",\t\"noisy_labels_5\", \"noisy_labels_25\", \"noisy_labels_50\"]):\n",
        "    create_noisy_datasets(df, col, idx+1)\n",
        "\n",
        "# setup()"
      ],
      "metadata": {
        "id": "SM-KlMDmHzXD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo val task=classify model=/content/noisy_0.onnx imgsz=224 data=/content/datasets/imagewoof2-160"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8r_j5jtEyPh",
        "outputId": "7d3a9502-3390-4732-8af9-7ebf7453d10a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.215 üöÄ Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Loading /content/noisy_0.onnx for ONNX Runtime inference...\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx', 'onnxruntime'] not found, attempting AutoUpdate...\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 15.7/15.7 MB 116.9 MB/s eta 0:00:00\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.4/6.4 MB 221.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 46.0/46.0 kB 216.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 86.8/86.8 kB 174.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.15.0 onnxruntime-1.16.3\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 16.9s, installed 2 packages: ['onnx', 'onnxruntime']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "Forcing batch=1 square inference (1,3,224,224) for non-PyTorch models\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/imagewoof2-160/train... found 9025 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/datasets/imagewoof2-160/val... found 3929 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/imagewoof2-160/val... 3929 images, 0 corrupt: 100% 3929/3929 [00:00<00:00, 4760.24it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/imagewoof2-160/val.cache\n",
            "               classes   top1_acc   top5_acc:   2% 68/3929 [00:01<00:48, 80.27it/s]Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "               classes   top1_acc   top5_acc:   3% 136/3929 [00:01<00:48, 78.87it/s]\n",
            "100% 755k/755k [00:00<00:00, 35.1MB/s]\n",
            "               classes   top1_acc   top5_acc: 100% 3929/3929 [00:52<00:00, 74.57it/s]\n",
            "                   all      0.847       0.99\n",
            "Speed: 0.0ms preprocess, 11.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/val\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo val task=classify model=/content/noisy_1.onnx imgsz=224 data=/content/datasets/noisy_labels_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auhcwCKyHYqe",
        "outputId": "1ca90a56-63af-4731-879b-d7157113142a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.215 üöÄ Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Loading /content/noisy_1.onnx for ONNX Runtime inference...\n",
            "Forcing batch=1 square inference (1,3,224,224) for non-PyTorch models\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/noisy_labels_1/train... found 9025 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/datasets/noisy_labels_1/val... found 3929 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/noisy_labels_1/val... 3929 images, 0 corrupt: 100% 3929/3929 [00:00<00:00, 4920.83it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/noisy_labels_1/val.cache\n",
            "               classes   top1_acc   top5_acc: 100% 3929/3929 [00:59<00:00, 66.04it/s]\n",
            "                   all      0.845      0.989\n",
            "Speed: 0.0ms preprocess, 12.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/val2\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo val task=classify model=/content/noisy_5.onnx imgsz=224 data=/content/datasets/noisy_labels_5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-9ZDN6eHZ-Y",
        "outputId": "f3951ee9-d631-4bd1-a0c6-192d0083d024"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.215 üöÄ Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Loading /content/noisy_5.onnx for ONNX Runtime inference...\n",
            "Forcing batch=1 square inference (1,3,224,224) for non-PyTorch models\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/noisy_labels_5/train... found 9025 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/datasets/noisy_labels_5/val... found 3929 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/noisy_labels_5/val... 3929 images, 0 corrupt: 100% 3929/3929 [00:00<00:00, 4161.13it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/noisy_labels_5/val.cache\n",
            "               classes   top1_acc   top5_acc: 100% 3929/3929 [00:59<00:00, 66.58it/s]\n",
            "                   all      0.833       0.99\n",
            "Speed: 0.0ms preprocess, 12.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/val3\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo val task=classify model=/content/noisy_25.onnx imgsz=224 data=/content/datasets/noisy_labels_25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfqGq69yHdDF",
        "outputId": "b91f5d32-f7b4-48b1-b6cc-5ac9671ff37a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.215 üöÄ Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Loading /content/noisy_25.onnx for ONNX Runtime inference...\n",
            "Forcing batch=1 square inference (1,3,224,224) for non-PyTorch models\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/noisy_labels_25/train... found 9025 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/datasets/noisy_labels_25/val... found 3929 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/noisy_labels_25/val... 3929 images, 0 corrupt: 100% 3929/3929 [00:01<00:00, 3899.18it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/noisy_labels_25/val.cache\n",
            "               classes   top1_acc   top5_acc: 100% 3929/3929 [00:56<00:00, 69.10it/s]\n",
            "                   all      0.793      0.984\n",
            "Speed: 0.0ms preprocess, 12.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/val4\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo val task=classify model=/content/noisy_50.onnx imgsz=224 data=/content/datasets/noisy_labels_50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B17RaEISIAlV",
        "outputId": "5c5b77ec-195c-466f-98ea-6af531f5788b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.215 üöÄ Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Loading /content/noisy_50.onnx for ONNX Runtime inference...\n",
            "Forcing batch=1 square inference (1,3,224,224) for non-PyTorch models\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/noisy_labels_50/train... found 9025 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/datasets/noisy_labels_50/val... found 3929 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/noisy_labels_50/val... 3929 images, 0 corrupt: 100% 3929/3929 [00:00<00:00, 4889.37it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/noisy_labels_50/val.cache\n",
            "               classes   top1_acc   top5_acc: 100% 3929/3929 [00:52<00:00, 74.28it/s]\n",
            "                   all      0.848      0.992\n",
            "Speed: 0.0ms preprocess, 11.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/val5\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    }
  ]
}